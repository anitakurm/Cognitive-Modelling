model {
  #priors
  
  w ~ dnorm(0,1)T(0,)
  A ~ dnorm(0,1)T(0,1) #assuming the person can't be risk seeking for gains, and can't be risk averse for losses = BASIS OF PROSPECT THEORY
  theta ~ dnorm(0,1)T(0,)
  a ~ dnorm(0,1)T(0,1)
  
  #inital feeling about the decks on the first trial
  Ev[1,1] ~ dnorm(0,0.1)
  Ev[1,2] ~ dnorm(0,0.1)
  Ev[1,3] ~ dnorm(0,0.1)
  Ev[1,4] ~ dnorm(0,0.1)

  p[1,1] <- .25 #deterministic assumption reasonable to make here
  p[1,2] <- .25
  p[1,3] <- .25
  p[1,4] <- .25

  #The model itself
  for (t in 2:ntrials){
    for (d in 1:4) { #for every deck
      u[t,d] <- ifelse(X[t-1]<0, -w*abs(X[t-1])^A,abs(X[t-1])^A)  #utility for trial t deck d; IF REWARD WAS LESS THAN 0, WE WANT TO TAKE ITS ABSOLUTE VALUE, take that number, put to the power of A for the curve and multiply by w; otherwise just put to the power of A
      
      Ev_update[t,d] <- Ev[t-1, d] +(a*(u[t,d] - Ev[t-1,d]))  #Update valence for every deck as if it was chosen: Expected valence on previous trial plus new information
      Ev[t,d] <- ifelse(x[t-1] == d, Ev_update[t,d], Ev[t-1, d])
      
      #softmax
      exp_p[t,d] <- exp(theta*Ev[t,d])
      
    }
    
    for (d in 1:4){
      p[t,d] <- exp_p[t,d]/sum(exp_p[t,])
    }
    
    #sample choice for the trial
    x[t] ~ dcat(p[t, ])
  }
}