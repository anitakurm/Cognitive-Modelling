model {
  
  #constrain the parameters
  alpha_rew ~ dunif(0,1) #the learning rate can only be between 0 and 1
  alpha_pun ~ dunif(0,1) #the learning rate can only be between 0 and 1
  
  beta_f ~ dnorm(0,0.1)
  beta_per ~ dnorm(0,0.1)
  
  theta <- 1
  K ~ dunif(0, 420)
  
  #inital feeling about the decks on the first trial
  Ev[1,1] ~ dnorm(0,0.1)
  Ev[1,2] ~ dnorm(0,0.1)
  Ev[1,3] ~ dnorm(0,0.1)
  Ev[1,4] ~ dnorm(0,0.1)
 
   #inital feeling about the decks on the first trial
  Ef[1,1] ~ dnorm(0,0.1)
  Ef[1,2] ~ dnorm(0,0.1)
  Ef[1,3] ~ dnorm(0,0.1)
  Ef[1,4] ~ dnorm(0,0.1) 
  
  #inital feeling about the decks on the first trial
  PS[1,1] ~ dnorm(0,0.1)
  PS[1,2] ~ dnorm(0,0.1)
  PS[1,3] ~ dnorm(0,0.1)
  PS[1,4] ~ dnorm(0,0.1) 
  
  p[1,1] <- .25 #deterministic assumption reasonable to make here
  p[1,2] <- .25
  p[1,3] <- .25
  p[1,4] <- .25
  
  
  #The model itself
  for (t in 2:ntrials){
    
    signX[t] <-  ifelse(X[t-1]<0,-1,1) #sign of the outcome (loss or gain)
    
    for (d in 1:4) { #for every deck 
      Ev_update[t,d] <- ifelse(X[t-1] >= 0, Ev[t-1, d] +(alpha_rew*(X[t-1] - Ev[t-1,d])) ,Ev[t-1, d] +(alpha_pun*(X[t-1] - Ev[t-1,d])))
      Ev[t,d] <- ifelse(x[t-1] == d, Ev_update[t,d], Ev[t-1, d])
      
      Ef_chosen[t,d] <- ifelse(X[t-1] >= 0, Ef[t-1, d] + (alpha_rew*(signX[t] - Ef[t-1, d])), Ef[t-1, d] + (alpha_pun*(signX[t] - Ef[t-1, d])))                                                     
      Ef_not[t,d] <- ifelse(X[t-1]>= 0, Ef[t-1, d] + (alpha_pun * ((-signX[t]/3)- Ef[t-1,d])), Ef[t-1, d] + (alpha_rew*((-signX[t]/3)- Ef[t-1,d])))
      Ef[t,d] <- ifelse(x[t-1] == d, Ef_chosen[t,d], Ef_not[t,d])
      
      PS[t,d] <- ifelse(x[t-1] == d, 1/(1+K), PS[t-1, d]/(1+K))
      
      V[t,d] <- Ev[t,d] + Ef[t,d]*beta_f + PS[t,d]*beta_per
      
      #softmax
      exp_p[t,d] <- exp(theta*V[t,d])
      }
    
    for (d in 1:4){
      p[t,d] <- exp_p[t,d]/sum(exp_p[t,])
    }
    
    #sample choice for the trial
    x[t] ~ dcat(p[t, ])
    

  }


}