---
title: "Module 3"
author: "Anita Kurm"
date: "3/11/2020"
output: html_document
---


# Set-up
```{r}
pacman::p_load(extraDistr, R2jags)
source("/Users/anitakurm/Desktop/Masters 2nd semester/Cognitive-Modelling/Module 1/quick_n_clean_plots.R")

```

Generarte task environment: Iowa gambling task
4 decks, the person is told both what they won but also what they lost

```{r}
#----------------------generate task environment

#Bad frequent
A_R <-  rep(100, 10) #reward for deck A: 10 rewards of 100kr (100 kr every time you choose Deck A)
A_L <- c(rep(-250, 5), rep(0,5)) #5 big losses, 5 no loss


#Bad infrequent
B_R <-  rep(100, 10) #reward for deck B: 10 rewards of 100kr if you choose Deck A
B_L <- c(rep(-1250, 1), rep(0,9))   #1 very big loss, 9 no loss

#Good frequent
C_R <-  rep(50, 10) #reward for deck A: 10 rewards of 100kr if you choose Deck A
C_L <- c(rep(-50, 5), rep(0,5))

#Good infrequent
D_R <-  rep(50, 10) #reward for deck A: 10 rewards of 100kr if you choose Deck A
D_L <- c(rep(-250, 1), rep(0,9))

A <-c()
for (i in 1:10){ A <- (append(A, A_R + sample(A_L)))} #take reward and loss, shuffle and add up all combinations, get 10*10 = 100 outcomes for decks 

B <-c()
for (i in 1:10){ B <- (append(B, B_R + sample(B_L)))}

C <-c()
for (i in 1:10){ C <- (append(C, C_R + sample(C_L)))}

D <-c()
for (i in 1:10){ D <- (append(D, D_R + sample(D_L)))}

payoff <- cbind(A,B,C,D)
```


```{r}
#build PVL-Delta model
w <- 2
A <- .5  #shape of the utility function, has to be between  0 and 1

theta <- .01 #response consistency in the softmax function
a <- .1 #learning rate, between 0 and 1

ntrials <- 100


source("PVL.R")
PVL_sims <- PVL(payoff, ntrials, w, A, a, theta=3)

par(mfrow=c(2,2))
plot(PVL_sims$Ev[,1])
plot(PVL_sims$Ev[,2])
plot(PVL_sims$Ev[,3])
plot(PVL_sims$Ev[,4])

```


## Parameter recovery

```{r}
x <- PVL_sims$x
X <-  PVL_sims$X

data <- list("x", "X", "ntrials")
params <- c("w", "A", "theta", "a")

samples <- jags.parallel(data, inits = NULL, params,
                model.file = "PVL_jags.txt",
                n.chains = 3, n.iter = 5000, n.burnin = 1000, n.thin = 1)
```




```{r}
  

######Just extra, to see what propsect theory parameters do



#---- plot prospect theory function for GAINS
  A <- .1
  objective_val <- seq(1,100, 1)
  subjective_util <- objective_val^A #prospect theory
  plot(objective_val, subjective_util)
  
  
  
  #---- plot prospect theory function for LOSS
  w <-  2 #loss aversion parameter
  A <- .1
  objective_val <- seq(1,100, 1)
  subjective_util <- -w*(objective_val^A) #prospect theory
  plot(objective_val, subjective_util)
```


